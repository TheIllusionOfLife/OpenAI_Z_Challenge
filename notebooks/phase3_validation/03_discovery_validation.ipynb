{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Discovery Validation and Archaeological Evaluation\n",
    "\n",
    "**Objective**: Validate potential archaeological sites identified by the models using archaeological literature and prepare for expert review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib # For loading saved scikit-learn models\n",
    "# import tensorflow as tf # If a TF model was saved\n",
    "\n",
    "# For displaying maps or coordinates, if needed\n",
    "# import folium \n",
    "# from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Trained Model and Potential Sites Data\n",
    "\n",
    "- Load the best performing model saved from Phase 2.\n",
    "- Load the data representing areas/points that the model predicted as potential archaeological sites. This might be a list of coordinates, polygons, or IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = '../../models/best_random_forest_model.joblib' # Example path\n",
    "POTENTIAL_SITES_DATA_PATH = '../../data/predicted/potential_sites.csv' # Example path\n",
    "\n",
    "try:\n",
    "    # loaded_model = joblib.load(MODEL_PATH)\n",
    "    # print(f\"Model loaded successfully from {MODEL_PATH}\")\n",
    "    print(f\"Conceptual: Load model from {MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at {MODEL_PATH}.\")\n",
    "    # loaded_model = None\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the model: {e}\")\n",
    "    # loaded_model = None\n",
    "\n",
    "try:\n",
    "    # potential_sites_df = pd.read_csv(POTENTIAL_SITES_DATA_PATH)\n",
    "    # print(f\"Potential sites data loaded. Shape: {potential_sites_df.shape}\")\n",
    "    # print(potential_sites_df.head())\n",
    "    print(f\"Conceptual: Load potential sites from {POTENTIAL_SITES_DATA_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Potential sites data file not found at {POTENTIAL_SITES_DATA_PATH}.\")\n",
    "    # potential_sites_df = None\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading potential sites data: {e}\")\n",
    "    # potential_sites_df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Archaeological Literature Data\n",
    "\n",
    "This data will be used to cross-reference and provide supporting evidence for the model's findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHAEOLOGICAL_LITERATURE_PATH = '../../data/raw/archaeological_lit.json' # Or processed version\n",
    "\n",
    "try:\n",
    "    with open(ARCHAEOLOGICAL_LITERATURE_PATH, 'r') as f:\n",
    "        archaeological_lit = json.load(f)\n",
    "    print(f\"Archaeological literature data loaded successfully.\")\n",
    "    # Potentially convert to a DataFrame or a more searchable structure if not done in Phase 1\n",
    "    # if isinstance(archaeological_lit, list):\n",
    "    #     archaeological_df = pd.DataFrame(archaeological_lit)\n",
    "    #     print(f\"Literature converted to DataFrame. Shape: {archaeological_df.shape}\")\n",
    "    #     # print(archaeological_df.head())\n",
    "    # else:\n",
    "    #     # Process dict or other structures as needed\n",
    "    #     pass\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Archaeological literature file not found at {ARCHAEOLOGICAL_LITERATURE_PATH}.\")\n",
    "    # archaeological_lit = None\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading archaeological literature: {e}\")\n",
    "    # archaeological_lit = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation Process\n",
    "\n",
    "The core of this phase is to check each potential site against available evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Extracting Information for Each Potential Site\n",
    "- For each site: coordinates, model confidence score, relevant features that led to the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if potential_sites_df is not None:\n",
    "#     print(\"Iterating through potential sites (conceptual):\")\n",
    "#     for index, site in potential_sites_df.iterrows():\n",
    "#         site_coords = (site.get('latitude'), site.get('longitude')) # Adjust column names\n",
    "#         site_confidence = site.get('model_confidence_score')\n",
    "#         print(f\"Site {index}: Coords={site_coords}, Confidence={site_confidence}\")\n",
    "#         # Further processing for each site will go here\n",
    "# else:\n",
    "#     print(\"Potential sites data not available.\")\n",
    "print(\"Conceptual: Extract information for each potential site.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Cross-Referencing with Archaeological Literature\n",
    "- For each potential site, search the archaeological literature for mentions, similar findings, or contextual information (e.g., proximity to known sites, LiDAR tile IDs, DOIs).\n",
    "- This might involve spatial joins (if literature has coordinates) or text-based searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_sites_info = []\n",
    "\n",
    "# def find_supporting_literature(site_coords, literature_data):\n",
    "#     # This is a placeholder for a more sophisticated search.\n",
    "#     # It could involve checking if site_coords fall within a known site's bounding box,\n",
    "#     # or if a LiDAR Tile ID associated with the site is mentioned in literature.\n",
    "#     # For simplicity, let's assume literature_data is a list of dicts with 'coords' and 'doi'.\n",
    "#     if not literature_data or not isinstance(literature_data, list):\n",
    "#         return None\n",
    "#     for record in literature_data:\n",
    "#         if 'coordinates' in record and 'doi' in record:\n",
    "#             # Example: check for exact coordinate match (highly unlikely in real scenarios)\n",
    "#             # A more realistic check would involve proximity search.\n",
    "#             lit_coords = tuple(record['coordinates']) \n",
    "#             if lit_coords == site_coords: # This needs to be a proximity check\n",
    "#                 return record['doi']\n",
    "#     return None\n",
    "\n",
    "# if potential_sites_df is not None and archaeological_lit is not None:\n",
    "#     print(\"Cross-referencing with literature (conceptual):\")\n",
    "#     for index, site in potential_sites_df.iterrows():\n",
    "#         site_coords = (site.get('latitude'), site.get('longitude')) # Adjust as needed\n",
    "#         supporting_doi = find_supporting_literature(site_coords, archaeological_lit) # archaeological_lit might need preprocessing\n",
    "        \n",
    "#         site_info = {\n",
    "#             'id': site.get('site_id', index),\n",
    "#             'latitude': site_coords[0],\n",
    "#             'longitude': site_coords[1],\n",
    "#             'model_confidence': site.get('model_confidence_score'),\n",
    "#             'supporting_doi': supporting_doi,\n",
    "#             'validation_notes': ''\n",
    "#         }\n",
    "#         if supporting_doi:\n",
    "#             site_info['validation_notes'] = f\"Supported by literature: {supporting_doi}\"\n",
    "#             print(f\"Site {site_coords} potentially supported by DOI: {supporting_doi}\")\n",
    "#         else:\n",
    "#             site_info['validation_notes'] = \"No direct support found in initial literature scan.\"\n",
    "#             print(f\"Site {site_coords} has no direct supporting literature in this scan.\")\n",
    "#         validated_sites_info.append(site_info)\n",
    "# else:\n",
    "#     print(\"Data for cross-referencing not available.\")\n",
    "print(\"Conceptual: Cross-reference with literature. This will involve spatial queries or text matching.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Confidence Scoring based on Validation\n",
    "- Assign a new confidence score or category based on the strength of evidence (e.g., 'High Confidence - Literature Supported', 'Medium Confidence - Model Predicted', 'Low Confidence - Needs Field Verification')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if validated_sites_info:\n",
    "#     for site_info in validated_sites_info:\n",
    "#         if site_info['supporting_doi']:\n",
    "#             site_info['final_confidence'] = 'High - Literature Supported'\n",
    "#         elif site_info['model_confidence'] > 0.8: # Example threshold\n",
    "#             site_info['final_confidence'] = 'Medium - Strong Model Prediction'\n",
    "#         else:\n",
    "#             site_info['final_confidence'] = 'Low - Model Suggestion'\n",
    "#     print(\"Final confidence scores assigned (conceptual).\")\n",
    "#     # validated_df = pd.DataFrame(validated_sites_info)\n",
    "#     # print(validated_df.head())\n",
    "# else:\n",
    "#     print(\"No validated site information to assign final confidence scores.\")\n",
    "print(\"Conceptual: Assign final confidence scores based on validation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Preparing Data for Expert Review\n",
    "\n",
    "- Compile a list of validated sites with all relevant information: coordinates, model output, supporting literature (if any), derived features, and the assigned validation confidence.\n",
    "- This list will be provided to archaeological experts as per the competition guidelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERT_REVIEW_OUTPUT_PATH = '../../data/processed/expert_review_candidates.csv'\n",
    "\n",
    "# if 'validated_df' in locals() and not validated_df.empty:\n",
    "#     # validated_df.to_csv(EXPERT_REVIEW_OUTPUT_PATH, index=False)\n",
    "#     print(f\"Data for expert review prepared and conceptually saved to {EXPERT_REVIEW_OUTPUT_PATH}\")\n",
    "# else:\n",
    "#     print(\"No validated data to prepare for expert review.\")\n",
    "print(f\"Conceptual: Save data for expert review to {EXPERT_REVIEW_OUTPUT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Next Steps\n",
    "\n",
    "- Document the findings from this validation phase.\n",
    "- Proceed to Phase 4 for final documentation and submission preparation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
