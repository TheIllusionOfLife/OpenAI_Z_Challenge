{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 1: Data Understanding and Preprocessing\n",
    "\n",
    "**Objective**: Understand the structure of the provided datasets and prepare them for analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configure visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Data Paths\n",
    "\n",
    "Assuming data is stored in the `../../data/raw/` directory relative to this notebook. Adjust paths as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to data files (replace with actual file names)\n",
    "LIDAR_PATH = '../../data/raw/lidar_data.tif' # Example path\n",
    "SATELLITE_IMAGE_PATH = '../../data/raw/satellite_image.tif' # Example path\n",
    "NDVI_DATA_PATH = '../../data/raw/ndvi_data.tif' # Example path\n",
    "GIS_DATA_PATH = '../../data/raw/gis_data.geojson' # Example path\n",
    "ARCHAEOLOGICAL_LITERATURE_PATH = '../../data/raw/archaeological_lit.json' # Example path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load and Inspect Data\n",
    "\n",
    "In this section, we will load each dataset and perform initial inspections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LiDAR Point Cloud Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with rasterio.open(LIDAR_PATH) as src:\n",
    "        lidar_data = src.read(1) # Read the first band\n",
    "        lidar_meta = src.meta\n",
    "    print(f\"LiDAR data loaded successfully. Shape: {lidar_data.shape}\")\n",
    "    print(f\"LiDAR metadata: {lidar_meta}\")\n",
    "    # Display a sample of the LiDAR data\n",
    "    # plt.imshow(lidar_data, cmap='terrain')\n",
    "    # plt.title('LiDAR Data Sample')\n",
    "    # plt.colorbar(label='Elevation')\n",
    "    # plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: LiDAR file not found at {LIDAR_PATH}. Please check the path.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading LiDAR data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations & Next Steps (LiDAR):**\n",
    "- Check data type, resolution, coordinate reference system (CRS).\n",
    "- Visualize the data to understand its spatial distribution.\n",
    "- Identify potential preprocessing needs: noise reduction, normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Satellite Imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with rasterio.open(SATELLITE_IMAGE_PATH) as src:\n",
    "        satellite_image = src.read() # Read all bands\n",
    "        satellite_meta = src.meta\n",
    "    print(f\"Satellite image loaded successfully. Shape: {satellite_image.shape}\")\n",
    "    print(f\"Satellite metadata: {satellite_meta}\")\n",
    "    # To display a true/false color composite, you might need to select specific bands\n",
    "    # For example, if RGB are bands 4, 3, 2 (1-indexed):\n",
    "    # rgb_image = satellite_image[[3, 2, 1], :, :] \n",
    "    # rgb_image_display = np.moveaxis(rgb_image, 0, -1) # Rearrange for plotting\n",
    "    # plt.imshow(rgb_image_display)\n",
    "    # plt.title('Satellite Image Sample')\n",
    "    # plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Satellite image file not found at {SATELLITE_IMAGE_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading satellite image: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations & Next Steps (Satellite):**\n",
    "- Check number of bands, data type, resolution, CRS.\n",
    "- Visualize different band combinations.\n",
    "- Preprocessing: cloud masking, atmospheric correction (if not already done)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 NDVI Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with rasterio.open(NDVI_DATA_PATH) as src:\n",
    "        ndvi_data = src.read(1)\n",
    "        ndvi_meta = src.meta\n",
    "    print(f\"NDVI data loaded successfully. Shape: {ndvi_data.shape}\")\n",
    "    print(f\"NDVI metadata: {ndvi_meta}\")\n",
    "    # plt.imshow(ndvi_data, cmap='RdYlGn')\n",
    "    # plt.title('NDVI Data Sample')\n",
    "    # plt.colorbar(label='NDVI Value')\n",
    "    # plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: NDVI file not found at {NDVI_DATA_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading NDVI data: {e}\")\n",
    "\n",
    "# If NDVI needs to be calculated from satellite bands (e.g., Red and NIR):\n",
    "# def calculate_ndvi(red_band, nir_band):\n",
    "#     # Ensure inputs are numpy arrays to prevent type errors\n",
    "#     red = red_band.astype(np.float32)\n",
    "#     nir = nir_band.astype(np.float32)\n",
    "#     # Prevent division by zero\n",
    "#     numerator = nir - red\n",
    "#     denominator = nir + red\n",
    "#     ndvi = np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=np.float32), where=denominator!=0)\n",
    "#     return ndvi\n",
    "\n",
    "# Assuming satellite_image has Red in band X and NIR in band Y (0-indexed)\n",
    "# if 'satellite_image' in locals() and satellite_image.ndim == 3 and satellite_image.shape[0] >= 4: # Basic check\n",
    "#     red_band_index = 3 # Example: band 4 (0-indexed)\n",
    "#     nir_band_index = 4 # Example: band 5 (0-indexed)\n",
    "#     calculated_ndvi = calculate_ndvi(satellite_image[red_band_index], satellite_image[nir_band_index])\n",
    "#     print(f\"Calculated NDVI shape: {calculated_ndvi.shape}\")\n",
    "#     # plt.imshow(calculated_ndvi, cmap='RdYlGn')\n",
    "#     # plt.title('Calculated NDVI')\n",
    "#     # plt.colorbar(label='NDVI Value')\n",
    "#     # plt.show()\n",
    "# else:\n",
    "#     print(\"Satellite image not available or does not have enough bands to calculate NDVI.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations & Next Steps (NDVI):**\n",
    "- Verify the range of NDVI values (typically -1 to +1).\n",
    "- Check CRS and resolution, ensure consistency with other raster data.\n",
    "- If NDVI is not provided directly, calculate it from satellite imagery (Red and NIR bands)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 GIS Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    gis_data = gpd.read_file(GIS_DATA_PATH)\n",
    "    print(f\"GIS data loaded successfully. Shape: {gis_data.shape}\")\n",
    "    print(f\"GIS data CRS: {gis_data.crs}\")\n",
    "    # print(gis_data.head())\n",
    "    # gis_data.plot(figsize=(10, 10), legend=True, column='land_use_type_example') # Replace with actual column\n",
    "    # plt.title('GIS Data Sample')\n",
    "    # plt.show()\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: GIS file not found at {GIS_DATA_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading GIS data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations & Next Steps (GIS):**\n",
    "- Examine attribute table for relevant features (e.g., land use, topography, hydrography).\n",
    "- Check geometry types (points, lines, polygons).\n",
    "- Ensure CRS is consistent with other datasets. Reproject if necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Archaeological Literature Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(ARCHAEOLOGICAL_LITERATURE_PATH, 'r') as f:\n",
    "        archaeological_lit = json.load(f)\n",
    "    print(f\"Archaeological literature data loaded successfully.\")\n",
    "    # print(json.dumps(archaeological_lit, indent=2, ensure_ascii=False)[:500]) # Print a sample\n",
    "\n",
    "    # If it's a list of records, convert to DataFrame for easier handling\n",
    "    # if isinstance(archaeological_lit, list):\n",
    "    #     archaeological_df = pd.DataFrame(archaeological_lit)\n",
    "    #     print(f\"Converted to DataFrame. Shape: {archaeological_df.shape}\")\n",
    "    #     print(archaeological_df.head())\n",
    "    # elif isinstance(archaeological_lit, dict): # Or some other structure\n",
    "    #     # Process dictionary as needed\n",
    "    #     print(\"Data is a dictionary. Inspect its structure for relevant information.\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Archaeological literature file not found at {ARCHAEOLOGICAL_LITERATURE_PATH}.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error: Could not decode JSON from {ARCHAEOLOGICAL_LITERATURE_PATH}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations & Next Steps (Archaeological Literature):**\n",
    "- Understand the structure of the data (JSON fields, nested objects).\n",
    "- Extract key information: site coordinates (if available), textual descriptions, DOI, LiDAR tile IDs, etc.\n",
    "- This data will be crucial for training (if labeled sites are provided) and for validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing Plan\n",
    "\n",
    "Based on initial exploration, outline the necessary preprocessing steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Handling Missing Values\n",
    "- **Strategy**: Identify missing values in each dataset. Decide on imputation (e.g., mean, median, mode, interpolation for rasters) or removal, depending on the extent and nature of missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for a pandas DataFrame (conceptual)\n",
    "# if 'some_df' in locals():\n",
    "#     print(some_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Coordinate System Unification\n",
    "- **Strategy**: Ensure all geospatial datasets (LiDAR, satellite, NDVI, GIS) share a common Coordinate Reference System (CRS). Reproject data if necessary. The target CRS should be suitable for the Amazon region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example for GeoPandas GeoDataFrame\n",
    "# if 'gis_data' in locals() and 'lidar_meta' in locals():\n",
    "#     target_crs = lidar_meta['crs'] # Assuming LiDAR CRS is the target\n",
    "#     if gis_data.crs != target_crs:\n",
    "#         print(f\"Reprojecting GIS data from {gis_data.crs} to {target_crs}\")\n",
    "#         # gis_data = gis_data.to_crs(target_crs)\n",
    "#         # print(f\"New GIS data CRS: {gis_data.crs}\")\n",
    "\n",
    "# For raster data with rasterio, reprojection is more complex and might involve `rasterio.warp.reproject`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Data Resampling/Alignment (for Rasters)\n",
    "- **Strategy**: If raster datasets (LiDAR, satellite, NDVI) have different resolutions or pixel alignments, they may need to be resampled to a common grid for combined analysis. Choose an appropriate resampling method (e.g., nearest neighbor, bilinear)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Feature Extraction (Examples)\n",
    "- **LiDAR**: Derive terrain features like slope, aspect, curvature, Digital Terrain Model (DTM), Canopy Height Model (CHM).\n",
    "- **Satellite/NDVI**: Extract textural features, additional vegetation indices.\n",
    "- **GIS**: Rasterize vector data (e.g., distance to rivers, land cover type) to align with raster grids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for feature extraction code\n",
    "# Example: Slope calculation from elevation data (conceptual)\n",
    "# if 'lidar_data' in locals():\n",
    "#     # slope_x, slope_y = np.gradient(lidar_data)\n",
    "#     # slope_rad = np.arctan(np.sqrt(slope_x**2 + slope_y**2))\n",
    "#     # slope_deg = np.degrees(slope_rad)\n",
    "#     # print(\"Slope calculated (conceptual).\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Data Normalization/Scaling\n",
    "- **Strategy**: For machine learning models, numerical features often need to be scaled (e.g., MinMaxScaler, StandardScaler) to a common range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "\n",
    "- Proceed with implementing the preprocessing steps outlined above.\n",
    "- Perform exploratory data analysis (EDA) on the cleaned and processed data to understand distributions, correlations, and identify potential patterns.\n",
    "- Begin feature engineering based on insights from EDA and domain knowledge."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
